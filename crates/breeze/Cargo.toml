[package]
name = "breeze"
version = "0.1.0"
edition = "2024"

[dependencies]
breeze-chunkers = { path = "../breeze-chunkers" }
arrow = { version = "55.1.0", features = ["prettyprint"] }
arrow_convert = "0.9.0"
lancedb = { version = "0.20.0" }
serde = { version = "1", features = ["derive"] }
serde_json = "1.0"
serde_arrow = "0.13.4"
uuid = { version = "1", features = ["v7", "serde", "zerocopy"] }
chrono = { version = "0.4", features = ["serde"] }
blake3 = { version = "1.8.2", features = ["serde"] }
tokio = { workspace = true }
pretty_env_logger = "0.5.0"
futures-util = "0.3.31"
async-trait = "0.1.88"

# Embedding providers
async-openai = "0.28"
reqwest = { version = "0.12", features = ["json", "stream"] }

# Local model support
candle-core = { version = "0.9" }
candle-nn = "0.9"
candle-transformers = "0.9"
hf-hub = "0.4"
tokenizers = { workspace = true }

# TEI backend support
text-embeddings-backend-core = { git = "https://github.com/huggingface/text-embeddings-inference", branch = "main" }
text-embeddings-backend-candle = { git = "https://github.com/huggingface/text-embeddings-inference", branch = "main" }
nohash-hasher = "0.2"

# Configuration and CLI
clap = { version = "4.5", features = ["derive"] }
config = "0.15"
toml = "0.8"

# Error handling
thiserror = "2.0"
anyhow = "1.0"

# Rate limiting and utilities
tokio-util = { version = "0.7", features = ["rt"] }
tokio-stream = "0.1"
async-stream = "0.3"

tracing = "0.1.41"
tracing-opentelemetry = "0.31.0"
tracing-subscriber = { version = "0.3.19", features = ["env-filter", "fmt"] }

num_cpus = "1"

[dev-dependencies]
tempfile = "3.11"

[features]
default = []
cuda = ["candle-core/cuda", "candle-nn/cuda", "candle-transformers/cuda"]
mkl = ["candle-core/mkl", "candle-nn/mkl", "candle-transformers/mkl"]
accelerate = ["candle-core/accelerate", "candle-nn/accelerate", "candle-transformers/accelerate"]
metal = ["candle-core/metal", "candle-nn/metal", "candle-transformers/metal"]
